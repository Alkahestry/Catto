{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender Classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5"
    },
    "metadata": {
      "interpreter": {
        "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
      }
    },
    "interpreter": {
      "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "# \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader\n",
        "# Dataset\n",
        "from CustomDataset import CatDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.8.1+cu111\nTorchvision Version:  0.9.1+cu111\nIs CUDA installed ?: True\nCUDA Version: 11.1\nUsing GPU.\n"
          ]
        }
      ],
      "source": [
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)\n",
        "print('Is CUDA installed ?:',torch.cuda.is_available())\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print('CUDA Version:',torch.version.cuda)\n",
        "    print('Using GPU.')\n",
        "else:\n",
        "  print('No CUDA is installed, using CPU instead.') \n",
        "  device = torch.device('CPU')"
      ]
    },
    {
      "source": [
        "-----------------------------------\n",
        "**No need to use anything below yet.**\n",
        "**Reserved for future run.**\n",
        "-----------------------------------\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Generate label file\n",
        "DATA_PATH = 'catset/labels'\n",
        "labelset = []\n",
        "for label in os.listdir(DATA_PATH):\n",
        "    end = len(label)\n",
        "    label = label[:(end-4)]+'.jpg'\n",
        "    labelset.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(labelset)\n",
        "df.insert(1, 'label', '0')\n",
        "df.reset_index(drop=True)\n",
        "df.head(5)\n",
        "df.to_csv('catset/labels.csv',\n",
        "            index=False,\n",
        "            header=False    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_data = CatDataset(csv_file='catset/labels.csv', root_dir='catset/images',transform=ToTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\viole/.cache\\torch\\hub\\master.zip\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7053910 parameters, 0 gradients, 16.3 GFLOPs\n",
            "Adding AutoShape... \n",
            "YOLOv5  b58658b torch 1.8.1+cu111 CUDA:0 (NVIDIA GeForce GTX 1650, 4096.0MB)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "catto = torch.hub.load('ultralytics/yolov5', 'custom', path='weight/YoloV5s_cat.pt',force_reload=True)  # Load Catto model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "IMG_PATH = 'training_data/images/'\n",
        "imgset = []\n",
        "for img in os.listdir(IMG_PATH):\n",
        "    imgset.append(IMG_PATH+img)\n",
        "len(imgset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 67.02039,  99.30237, 563.27728, 506.26453,   0.86711,   0.00000]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "catto.cpu()\n",
        "results = catto(imgset, size=320)  # custom inference size\n",
        "results.xyxy[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 1 (1).jpg, 1 (10).jpg, 1 (11).jpg, 1 (12).jpg, 1 (13).jpg, 1 (14).jpg, 1 (15).jpg, 1 (16).jpg, 1 (17).jpg, 1 (18).jpg, 1 (19).jpg, 1 (2).jpg, 1 (20).jpg, 1 (21).jpg, 1 (22).jpg, 1 (23).jpg, 1 (3).jpg, 1 (4).jpg, 1 (5).jpg, 1 (6).jpg, 1 (7).jpg, 1 (8).jpg, 1 (9).jpg to runs\\hub\\exp7\n"
          ]
        }
      ],
      "source": [
        "results.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}